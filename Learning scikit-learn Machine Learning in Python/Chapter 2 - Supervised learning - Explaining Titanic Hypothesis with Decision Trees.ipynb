{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Scikit-learn: Machine Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Chapter 2: Supervised Learning: Explaining Titanic Hypothesis with Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must load the dataset. We assume it is located in the data/titanic.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['row.names' 'pclass' 'survived' 'name' 'age' 'embarked' 'home.dest'\n",
      " 'room' 'ticket' 'boat' 'sex']\n",
      "First 5 rows of Data:\n",
      "[['1' '1st' '1' 'Allen, Miss Elisabeth Walton' '29.0000' 'Southampton'\n",
      "  'St Louis, MO' 'B-5' '24160 L221' '2' 'female']\n",
      " ['2' '1st' '0' 'Allison, Miss Helen Loraine' ' 2.0000' 'Southampton'\n",
      "  'Montreal, PQ / Chesterville, ON' 'C26' '' '' 'female']\n",
      " ['3' '1st' '0' 'Allison, Mr Hudson Joshua Creighton' '30.0000'\n",
      "  'Southampton' 'Montreal, PQ / Chesterville, ON' 'C26' '' '(135)' 'male']\n",
      " ['4' '1st' '0' 'Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)'\n",
      "  '25.0000' 'Southampton' 'Montreal, PQ / Chesterville, ON' 'C26' '' ''\n",
      "  'female']\n",
      " ['5' '1st' '1' 'Allison, Master Hudson Trevor' ' 0.9167' 'Southampton'\n",
      "  'Montreal, PQ / Chesterville, ON' 'C22' '' '11' 'male']]\n",
      "First 5 Target Values:\n",
      "['1' '0' '0' '0' '1']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open('data/titanic.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    titanic_reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # Header contains feature names\n",
    "    feature_names = np.array(next(titanic_reader))\n",
    "    \n",
    "    # Load dataset and target classes\n",
    "    titanic_X, titanic_y = [], []\n",
    "    for row in titanic_reader:\n",
    "        titanic_X.append(row)\n",
    "        titanic_y.append(row[2]) # The target value is \"survived\"\n",
    "    \n",
    "    titanic_X = np.array(titanic_X)\n",
    "    titanic_y = np.array(titanic_y)\n",
    "\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"First 5 rows of Data:\")\n",
    "print(titanic_X[:5])\n",
    "print(\"First 5 Target Values:\")\n",
    "print(titanic_y[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row.names' 'pclass' 'survived' 'name' 'age' 'embarked' 'home.dest'\n",
      " 'room' 'ticket' 'boat' 'sex'] ['1' '1st' '1' 'Allen, Miss Elisabeth Walton' '29.0000' 'Southampton'\n",
      " 'St Louis, MO' 'B-5' '24160 L221' '2' 'female'] 1\n"
     ]
    }
   ],
   "source": [
    "print (feature_names, titanic_X[0], titanic_y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only class (1st,2nd,3rd), age (float), and sex (masc, fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep the class, the age and the sex\n",
    "titanic_X = titanic_X[:, [1, 4, 10]]\n",
    "feature_names = feature_names[[1, 4, 10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pclass' 'age' 'sex']\n",
      "['1st' 'NA' 'female'] 1\n"
     ]
    }
   ],
   "source": [
    "print (feature_names)\n",
    "print (titanic_X[12], titanic_y[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve missing values ('NA') for the 'age' feature. Solution: use the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['row.names' 'pclass' 'survived' 'name' 'age' 'embarked' 'home.dest'\n",
      " 'room' 'ticket' 'boat' 'sex']\n",
      "First 5 rows of Data:\n",
      "[[1 '1st' 1 'Allen, Miss Elisabeth Walton' 29.0 'Southampton'\n",
      "  'St Louis, MO' 'B-5' '24160 L221' '2' 'female']\n",
      " [2 '1st' 0 'Allison, Miss Helen Loraine' 2.0 'Southampton'\n",
      "  'Montreal, PQ / Chesterville, ON' 'C26' nan nan 'female']\n",
      " [3 '1st' 0 'Allison, Mr Hudson Joshua Creighton' 30.0 'Southampton'\n",
      "  'Montreal, PQ / Chesterville, ON' 'C26' nan '(135)' 'male']\n",
      " [4 '1st' 0 'Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)' 25.0\n",
      "  'Southampton' 'Montreal, PQ / Chesterville, ON' 'C26' nan nan 'female']\n",
      " [5 '1st' 1 'Allison, Master Hudson Trevor' 0.9167 'Southampton'\n",
      "  'Montreal, PQ / Chesterville, ON' 'C22' nan '11' 'male']]\n",
      "First 5 Target Values:\n",
      "[1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('data/titanic.csv', delimiter=',', quotechar='\"')\n",
    "\n",
    "# Replace 'unknown' with NaN in the 'age' column\n",
    "data['age'] = data['age'].replace('unknown', np.nan)\n",
    "\n",
    "# Convert the 'age' column to numeric, forcing errors to NaN\n",
    "data['age'] = pd.to_numeric(data['age'], errors='coerce')\n",
    "\n",
    "# Fill NaN values in the 'age' column with the mean age\n",
    "mean_age = data['age'].mean()\n",
    "data['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "titanic_X = data.values\n",
    "\n",
    "# Extract the feature names and target variable\n",
    "feature_names = data.columns.values\n",
    "titanic_y = data['survived'].values\n",
    "\n",
    "print(\"Feature Names:\", feature_names)\n",
    "print(\"First 5 rows of Data:\")\n",
    "print(titanic_X[:5])\n",
    "print(\"First 5 Target Values:\")\n",
    "print(titanic_y[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row.names' 'pclass' 'survived' 'name' 'age' 'embarked' 'home.dest'\n",
      " 'room' 'ticket' 'boat' 'sex']\n",
      "[13 '1st' 1 'Aubert, Mrs Leontine Pauline' 31.19418104265403 'Cherbourg'\n",
      " 'Paris, France' 'B-35' '17477 L69 6s' '9' 'female'] 1\n"
     ]
    }
   ],
   "source": [
    "print (feature_names)\n",
    "print (titanic_X[12], titanic_y[12])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class and sex are categorical classes. Sex can be converted to a binary value (0=female,1=male):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical classes: [0 1]\n",
      "Integer classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Encode sex \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(titanic_X[:, 2])\n",
    "print (\"Categorical classes:\", label_encoder.classes_)\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_)\n",
    "print (\"Integer classes:\", integer_classes)\n",
    "t = label_encoder.transform(titanic_X[:, 2])\n",
    "titanic_X[:, 2] = t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['row.names' 'pclass' 'survived' 'name' 'age' 'embarked' 'home.dest'\n",
      " 'room' 'ticket' 'boat' 'sex']\n",
      "[13 '1st' 1 'Aubert, Mrs Leontine Pauline' 31.19418104265403 'Cherbourg'\n",
      " 'Paris, France' 'B-35' '17477 L69 6s' '9' 'female'] 1\n"
     ]
    }
   ],
   "source": [
    "print (feature_names)\n",
    "print (titanic_X[12], titanic_y[12])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to convert the class. Since we have three different classes, we cannot convert to binary values (and using 0/1/2 values would imply an order, something we do not want). We use OneHotEncoder to get three different attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with One-Hot Encoded 'pclass' column:\n",
      "       id  survived  sex  age  sibsp  parch     fare  embarked  class_1  \\\n",
      "0  129237         0    1   22      1      0   7.2500         1      0.0   \n",
      "1  123083         1    0   38      1      0  71.2833         0      1.0   \n",
      "2  123087         1    0   26      0      0   7.9250         1      0.0   \n",
      "\n",
      "   class_2  \n",
      "0      1.0  \n",
      "1      0.0  \n",
      "2      1.0  \n",
      "Updated feature names: ['id', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class_1', 'class_2']\n",
      "Feature matrix (titanic_X):\n",
      "[[1.29237e+05 1.00000e+00 2.20000e+01 1.00000e+00 0.00000e+00 7.25000e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00]\n",
      " [1.23083e+05 0.00000e+00 3.80000e+01 1.00000e+00 0.00000e+00 7.12833e+01\n",
      "  0.00000e+00 1.00000e+00 0.00000e+00]\n",
      " [1.23087e+05 0.00000e+00 2.60000e+01 0.00000e+00 0.00000e+00 7.92500e+00\n",
      "  1.00000e+00 0.00000e+00 1.00000e+00]]\n",
      "Target vector (titanic_y):\n",
      "[0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Sample dataset to emulate the Titanic dataset structure\n",
    "data = {\n",
    "    'id': [129237, 123083, 123087],\n",
    "    'name': ['Braund, Mr. Owen Harris', 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Heikkinen, Miss. Laina'],\n",
    "    'survived': [0, 1, 1],\n",
    "    'pclass': [3, 1, 3],\n",
    "    'sex': ['male', 'female', 'female'],\n",
    "    'age': [22, 38, 26],\n",
    "    'sibsp': [1, 1, 0],\n",
    "    'parch': [0, 0, 0],\n",
    "    'ticket': ['A/5 21171', 'PC 17599', 'STON/O2. 3101282'],\n",
    "    'fare': [7.25, 71.2833, 7.925],\n",
    "    'cabin': ['', 'C85', ''],\n",
    "    'embarked': ['S', 'C', 'S']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert categorical features to numerical values using LabelEncoder\n",
    "label_encoders = {}\n",
    "for column in ['sex', 'embarked']:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Apply OneHotEncoder to the 'pclass' column\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "pclass_reshaped = df[['pclass']].values.reshape(-1, 1)\n",
    "pclass_one_hot = enc.fit_transform(pclass_reshaped)\n",
    "\n",
    "# Add the one-hot encoded columns to the original DataFrame\n",
    "pclass_df = pd.DataFrame(pclass_one_hot, columns=[f'class_{int(i)}' for i in range(1, pclass_one_hot.shape[1] + 1)])\n",
    "df = pd.concat([df, pclass_df], axis=1)\n",
    "\n",
    "# Drop the original 'pclass', 'name', 'ticket', and 'cabin' columns\n",
    "df.drop(columns=['pclass', 'name', 'ticket', 'cabin'], inplace=True)\n",
    "\n",
    "# Display the DataFrame with the new features\n",
    "print(\"DataFrame with One-Hot Encoded 'pclass' column:\")\n",
    "print(df)\n",
    "\n",
    "# Update feature names\n",
    "feature_names = df.columns.tolist()\n",
    "print(\"Updated feature names:\", feature_names)\n",
    "\n",
    "# Convert to numpy arrays for further processing\n",
    "titanic_X = df.drop(columns=['survived']).values\n",
    "titanic_y = df['survived'].values\n",
    "\n",
    "# Convert to float for numerical computations\n",
    "titanic_X = titanic_X.astype(float)\n",
    "titanic_y = titanic_y.astype(float)\n",
    "\n",
    "# Print the feature matrix and target vector\n",
    "print(\"Feature matrix (titanic_X):\")\n",
    "print(titanic_X)\n",
    "print(\"Target vector (titanic_y):\")\n",
    "print(titanic_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class_1', 'class_2']\n",
      "[1.29237e+05 1.00000e+00 2.20000e+01 1.00000e+00 0.00000e+00 7.25000e+00\n",
      " 1.00000e+00 0.00000e+00 1.00000e+00] 0.0\n"
     ]
    }
   ],
   "source": [
    "print (feature_names)\n",
    "print (titanic_X[0], titanic_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.25, random_state=33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a decision tree with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the built tree, using pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m graph \u001b[38;5;241m=\u001b[39m pydotplus\u001b[38;5;241m.\u001b[39mgraph_from_dot_data(dot_data\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Save the graph as a PNG file\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m graph\u001b[38;5;241m.\u001b[39mwrite_png(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miris.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n\u001b[1;32m     35\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miris.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pydotplus/graphviz.py:1810\u001b[0m, in \u001b[0;36mDot.__init__.<locals>.<lambda>\u001b[0;34m(path, f, prog)\u001b[0m\n\u001b[1;32m   1800\u001b[0m     f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1801\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m''''create' method for more information.'''\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m     )\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frmt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformats \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\n\u001b[1;32m   1807\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m frmt,\n\u001b[1;32m   1808\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m path,\n\u001b[1;32m   1809\u001b[0m         f\u001b[38;5;241m=\u001b[39mfrmt,\n\u001b[0;32m-> 1810\u001b[0m         prog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(path, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mf, prog\u001b[38;5;241m=\u001b[39mprog)\n\u001b[1;32m   1811\u001b[0m     )\n\u001b[1;32m   1813\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m frmt]\n\u001b[1;32m   1814\u001b[0m     f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m''''write' method for more information.'''\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pydotplus/graphviz.py:1918\u001b[0m, in \u001b[0;36mDot.write\u001b[0;34m(self, path, prog, format)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         fobj\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m         fobj\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate(prog, \u001b[38;5;28mformat\u001b[39m))\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m close:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pydotplus/graphviz.py:1959\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogs \u001b[38;5;241m=\u001b[39m find_graphviz()\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1959\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvocationException(\n\u001b[1;32m   1960\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphViz\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms executables not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prog \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogs:\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvocationException(\n\u001b[1;32m   1964\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphViz\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms executable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m prog)\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from io import StringIO\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "# Ensure the Graphviz path is added to the system PATH environment variable\n",
    "os.environ[\"PATH\"] += os.pathsep + r'/usr/local/bin'\n",
    "\n",
    "# Load example dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Train the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "# Generate DOT data\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file=dot_data, \n",
    "                     feature_names=iris.feature_names,  \n",
    "                     class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)\n",
    "\n",
    "# Create graph from DOT data\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "# Save the graph as a PNG file\n",
    "graph.write_png(\"iris.png\")\n",
    "\n",
    "# Display the image\n",
    "Image(filename=\"iris.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure Accuracy, precision, recall, f1 in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Training Data:\n",
      "Accuracy: 1.000\n",
      "Performance on Test Data:\n",
      "Accuracy: 1.000\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Confusion Matrix\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Function to measure performance\n",
    "def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred = clf.predict(X)\n",
    "    \n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy: {0:.3f}\".format(metrics.accuracy_score(y, y_pred)))\n",
    "    \n",
    "    if show_classification_report:\n",
    "        print(\"Classification Report\")\n",
    "        print(metrics.classification_report(y, y_pred))\n",
    "    \n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(metrics.confusion_matrix(y, y_pred))\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Measure performance on training data\n",
    "print(\"Performance on Training Data:\")\n",
    "measure_performance(X_train, y_train, clf, show_classification_report=False, show_confusion_matrix=False)\n",
    "\n",
    "# Measure performance on test data\n",
    "print(\"Performance on Test Data:\")\n",
    "measure_performance(X_test, y_test, clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform leave-one-out cross validation to better measure performance, reducing variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.953 (+/-0.017)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def loo_cv(X_train, y_train, clf):\n",
    "    # Perform Leave-One-Out cross-validation\n",
    "    loo = LeaveOneOut()\n",
    "    scores = np.zeros(X_train.shape[0])\n",
    "    \n",
    "    for train_index, test_index in loo.split(X_train):\n",
    "        X_train_cv, X_test_cv = X_train[train_index], X_train[test_index]\n",
    "        y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "        clf = clf.fit(X_train_cv, y_train_cv)\n",
    "        y_pred = clf.predict(X_test_cv)\n",
    "        scores[test_index] = metrics.accuracy_score(y_test_cv, y_pred)\n",
    "    \n",
    "    print(\"Mean score: {0:.3f} (+/-{1:.3f})\".format(np.mean(scores), sem(scores)))\n",
    "\n",
    "# Load example dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Train a classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Perform Leave-One-Out cross-validation\n",
    "loo_cv(X, y, clf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.924 (+/-0.026)\n"
     ]
    }
   ],
   "source": [
    "loo_cv(X_train, y_train,clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve performance using Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.924 (+/-0.026)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=10,random_state=33)\n",
    "clf = clf.fit(X_train,y_train)\n",
    "loo_cv(X_train,y_train,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate performance on future data, evaluate on the training set and test on the evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Confusion Matrix\n",
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "clf_dt=tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
    "clf_dt.fit(X_train,y_train)\n",
    "measure_performance(X_test,y_test,clf_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
